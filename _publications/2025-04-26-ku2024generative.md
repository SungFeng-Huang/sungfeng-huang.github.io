---
title: "Generative Speech Foundation Model Pretraining for High-Quality Speech Extraction and Restoration"
collection: publications
permalink: /publication/2025-04-26-ku2024generative
authors: 'Pin-Jui Ku, Alexander H. Liu, Roman Korostik, <u>Sung-Feng Huang</u>, Szu-Wei Fu, Ante Jukić'
excerpt: 'Foundation flow-matching model for generation tasks'
date: 2025-04-26
venue: 'IEEE ICASSP'
paperurl: 'https://arxiv.org/abs/2409.16117'
citation: 'Ku, P. J., Liu, A. H., Korostik, R., Huang, S. F., Fu, S. W., &amp; Jukić, A. (2024). Generative speech foundation model pretraining for high-quality speech extraction and restoration. arXiv preprint arXiv:2409.16117.'
---

Abstract:
---
This paper proposes a generative pretraining foundation model for high-quality speech restoration tasks. By directly operating on complex-valued short-time Fourier transform coefficients, our model does not rely on any vocoders for time-domain signal reconstruction. As a result, our model simplifies the synthesis process and removes the quality upper-bound introduced by any mel-spectrogram vocoder compared to prior work SpeechFlow. The proposed method is evaluated on multiple speech restoration tasks, including speech denoising, bandwidth extension, codec artifact removal, and target speaker extraction. In all scenarios, finetuning our pretrained model results in superior performance over strong baselines. Notably, in the target speaker extraction task, our model outperforms existing systems, including those leveraging SSL-pretrained encoders like WavLM. The code and the pretrained checkpoints are publicly available in the NVIDIA NeMo framework.
