---
title: "Learning Phone Recognition From Unpaired Audio and Phone Sequences Based on Generative Adversarial Network
"
collection: publications
permalink: /publication/2021-12-18-liu2021learning
authors: 'Da-rong Liu, Po-chun Hsu, Yi-chen Chen, <u>Sung-feng Huang</u>, Shun-po Chuang, Da-yi Wu, Hung-yi Lee'
excerpt: 'Unsupervised ASR'
date: 2021-12-18
venue: 'IEEE/ACM TASLP'
paperurl: 'https://ieeexplore.ieee.org/abstract/document/9664381/'
citation: 'Liu, Da-rong, Po-chun Hsu, Yi-chen Chen, Sung-feng Huang, Shun-po Chuang, Da-yi Wu, and Hung-yi Lee. &quot;Learning phone recognition from unpaired audio and phone sequences based on generative adversarial network.&quot; IEEE/ACM transactions on audio, speech, and language processing 30 (2021): 230-243.'
---

Abstract:
---
ASR has been shown to achieve great performance recently. However, most of them rely on massive paired data, which is not feasible for low-resource languages worldwide. This paper investigates how to learn directly from unpaired phone sequences and speech utterances. We design a two-stage iterative framework. GAN training is adopted in the first stage to find the mapping relationship between unpaired speech and phone sequence. In the second stage, another HMM model is introduced to train from the generatorâ€™s output, which boosts the performance and provides a better segmentation for the next iteration. In the experiment, we first investigate different choices of model designs. Thenwe compare the framework to different types of baselines: (i) supervised methods (ii) acoustic unit discovery based methods (iii) methods learning from unpaired data. Our framework performs consistently better than all acoustic unit discovery methods and previous methods learning from unpaired data based on the TIMIT dataset.
